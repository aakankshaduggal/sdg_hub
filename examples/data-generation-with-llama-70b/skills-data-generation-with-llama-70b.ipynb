{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Data Generation for Skills Tutorial using LLaMA\n",
    "\n",
    "**Key Update:**\n",
    "The biggest change in this improved workflow is that we use the Llama model to directly classify samples into skill routes using guided choices. This replaces the earlier approach where LoRA adapters were used with Mixtral for routing/classification. This new method leverages Llama's strong multi-class classification ability and simplifies the workflow by removing the need for adapter-based routing.\n",
    "\n",
    "This tutorial demonstrates how to use the SDG repository to generate synthetic question-answer pairs from documents using large language models like LLaMA 3.3 70B. We will also generate data using the Mixtral model for comparison. We'll cover:\n",
    "\n",
    "1. Setting up the environment\n",
    "2. Connecting to LLM servers\n",
    "3. Configuring the data generation pipeline\n",
    "4. Generating data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable auto-reloading of modules - useful during development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Instructions\n",
    "\n",
    "Before running this notebook, you'll need to:\n",
    "\n",
    "```bash \n",
    "pip install sdg-hub==0.1.0a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "# datasets: For handling our data\n",
    "# OpenAI: For interfacing with the LLM servers\n",
    "# SDG components: For building our data generation pipeline\n",
    "from datasets import load_dataset, Dataset\n",
    "from openai import OpenAI\n",
    "\n",
    "from sdg_hub.flow import Flow\n",
    "from sdg_hub.pipeline import Pipeline\n",
    "from sdg_hub.sdg import SDG\n",
    "from sdg_hub.registry import PromptRegistry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up LLaMA 3.3 70B Model\n",
    "\n",
    "First, we need to host the LLaMA model using vLLM. This creates an OpenAI-compatible API endpoint.\n",
    "\n",
    "1. Start the vLLM server (run in terminal):\n",
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -m vllm.entrypoints.openai.api_server \\\n",
    "    --model meta-llama/Llama-3.3-70B-Instruct \\\n",
    "    --dtype float16 \\\n",
    "    --tensor-parallel-size 8 \n",
    "```\n",
    "\n",
    "2. Connect to the model using OpenAI client below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI client to connect to our local vLLM server\n",
    "endpoint = f\"http://localhost:8000/v1\"\n",
    "openai_api_key = \"EMPTY\"  # vLLM doesn't require real API key\n",
    "openai_api_base = endpoint\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "# Verify we can see the model\n",
    "teacher_model = client.models.list().data[0].id\n",
    "print(f\"Connected to model: {teacher_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure and Chain Data Generation Pipelines\n",
    "In this section, we'll demonstrate how to chain two Synthetic Data Generation (SDG) pipelines using two different flow YAML configurations. This is useful when you want to perform multi-stage data processing, such as generating initial data with one pipeline and then refining, critiquing, or further processing it with a second pipeline.\n",
    "#### Steps:\n",
    "1. **Load SDG Flow configurations from YAML:**\n",
    "* `synth-skills-llama3.3.yaml` for the first stage (e.g., initial data generation)\n",
    "* `agentic-skills-llama3.3.yaml` for the second stage (e.g., skill routing, critique, revision etc)\n",
    "2. **Initialize the SDG pipeline with both flows:**\n",
    "* Pass both flow configurations as a list of Pipeline objects to a single SDG instance.\n",
    "* Set processing parameters such as batch_size, num_workers, and save_freq.\n",
    "3. **Run the chained pipeline:**\n",
    "The SDG pipeline will automatically process your dataset through each stage in sequence, passing the output of one pipeline as the input to the next.\n",
    "\n",
    "This approach allows for modular, flexible, and reusable data generation workflows, where each pipeline can focus on a specific stage of the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the flow configuration from YAML file\n",
    "flow_cfg1 = Flow(client).get_flow_from_file(\"synth-skills-llama3.3.yaml\")\n",
    "flow_cfg2 = Flow(client).get_flow_from_file(\"agentic-skills-llama3.3.yaml\")\n",
    "\n",
    "# Initialize the SDG pipeline with processing parameters\n",
    "pipeline = SDG(\n",
    "    [Pipeline(flow_cfg1), Pipeline(flow_cfg2)],\n",
    "    num_workers=1,      # Number of parallel workers\n",
    "    batch_size=1,       # Batch size for processing\n",
    "    save_freq=1000,     # How often to save checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Seed Data\n",
    "We will import the skills sample data set to generate question-answer pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the seed data from JSON file\n",
    "seed_data_path = \"../instructlab/skills/sample_data/unstructured_to_mdtable_seeds.jsonl\"  # You can replace with your data path here.\n",
    "ds = load_dataset('json', data_files=seed_data_path, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing, we'll use just two examples\n",
    "ds = ds.select(range(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data with LLaMA 3.3\n",
    "\n",
    "Now we'll use our configured pipeline to generate synthetic question-answer pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data and save checkpoints\n",
    "generated_data = pipeline.generate(ds, checkpoint_dir=\"Tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples:\n",
    "\n",
    "Each example below shows the generated sample content along with the route assigned by the Llama 3.3 model, illustrating how the model classifies different types of input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_description': 'Convert the following unstructured user feedback into a structured markdown table.',\n",
       " 'seed_question': \"Been using the new dashboard for a few days. It's way faster than the previous one, really appreciate the snappy filters. But export to CSV seems broken â€” nothing happens when I click it. Also, dark mode resets every time I log in.\\n\\nI would like to convert the above feedback into a markdown table with columns for Feature, Feedback and Sentiment.\",\n",
       " 'seed_response': \"| Feature           | Feedback                                                           | Sentiment |\\n|------------------|--------------------------------------------------------------------|-----------|\\n| Dashboard        | Much faster than previous version, filters are responsive.         | Positive  |\\n| Export to CSV    | Clicking the export button doesn't trigger a download.             | Negative  |\\n| Dark Mode        | Resets to light mode on login.                                     | Negative  |\",\n",
       " 'question': \"I recently purchased a new smartwatch and I'm having trouble setting up the notification system. The user manual is unclear, and I've tried following the online tutorials, but nothing seems to work. I love the design and battery life, though. How can I convert this feedback into a markdown table with columns for Feature, Issue, and Overall Satisfaction?\",\n",
       " 'response': '| Feature           | Issue                                                             | Overall Satisfaction |\\n|------------------|--------------------------------------------------------------------|----------------------|\\n| Notification System | Difficulty in setting up, unclear user manual and online tutorials | Negative             |\\n| Design            | Attractive and appealing design                                   | Positive             |\\n| Battery Life      | Long-lasting battery life                                         | Positive             |',\n",
       " 'route': 'writing',\n",
       " 'analysis': 'The task involves converting user feedback about a smartwatch into a markdown table. The domain is technology and product review. The user specifically requests assistance with organizing their feedback into a table format with columns for Feature, Issue, and Overall Satisfaction, indicating a need for a structured and clear presentation of their experience. Keywords such as \"markdown table\" and specific column names emphasize the requirement for a particular output format. The user\\'s feedback includes both positive and negative aspects of the smartwatch, suggesting the need to capture both in the table.',\n",
       " 'rubric': \"1. Feature Description: Are the features of the smartwatch (e.g., notification system, design, battery life) clearly and accurately described in the markdown table?\\n2. Issue Identification: Are the issues encountered with the smartwatch (e.g., setting up the notification system) specifically stated and associated with the relevant feature in the table?\\n3. Satisfaction Rating: Is the overall satisfaction with each feature (or the smartwatch as a whole) effectively conveyed in the table, using a scale or descriptive terms that align with the Overall Satisfaction column?\\n4. Table Format: Is the feedback correctly formatted into a markdown table with the requested columns (Feature, Issue, Overall Satisfaction), and is the table easy to read and understand?\\n5. Clarity and Completeness: Does the table comprehensively cover all aspects of the user's feedback, including both positive and negative experiences, and is the information presented in a clear and concise manner?\",\n",
       " 'critique': '1. Feature Description: The features of the smartwatch, such as the notification system, design, and battery life, are clearly and accurately described in the markdown table. Each feature is succinctly named, making it easy to identify and understand the aspects of the smartwatch being evaluated.\\n\\n2. Issue Identification: The issues encountered with the smartwatch are specifically stated and associated with the relevant feature in the table. For example, the difficulty in setting up the notification system is clearly linked to the \"Notification System\" feature, providing a direct connection between the feature and the problem experienced.\\n\\n3. Satisfaction Rating: The overall satisfaction with each feature is effectively conveyed in the table through the use of descriptive terms like \"Negative\" and \"Positive\" in the Overall Satisfaction column. This scale is simple and easy to understand, immediately conveying the user\\'s satisfaction level with each feature.\\n\\n4. Table Format: The feedback is correctly formatted into a markdown table with the requested columns (Feature, Issue, Overall Satisfaction). The table is well-structured, easy to read, and understand, making it a effective tool for quickly grasping the user\\'s feedback about the smartwatch.\\n\\n5. Clarity and Completeness: The table comprehensively covers all aspects of the user\\'s feedback, including both positive (design and battery life) and negative (notification system setup) experiences. The information is presented in a clear and concise manner, with each feature, its associated issue (if any), and the overall satisfaction level clearly stated. This makes the table a complete and useful summary of the user\\'s experience with the smartwatch.\\n\\nOverall, the response effectively meets the criteria outlined in the rubric, providing a clear, comprehensive, and well-formatted markdown table that accurately represents the user\\'s feedback about their smartwatch. The table\\'s clarity and completeness make it a valuable tool for understanding the user\\'s experience, highlighting both the strengths and weaknesses of the product.',\n",
       " 'plan': '1. **Enhance Feature Descriptions**: Consider adding a brief description or explanation for each feature in the table to provide context for readers who may not be familiar with the smartwatch\\'s capabilities. This could include a short phrase or sentence that expands on what each feature entails.\\n\\n2. **Specify Issue Details**: For issues like the notification system setup, provide more specific details about the problem encountered, such as what steps were taken, what was expected, and what actually happened. This could involve expanding the \"Issue\" column to include more descriptive text or adding a separate column for \"Expected Outcome\" versus \"Actual Outcome\".\\n\\n3. **Quantify Satisfaction**: Instead of using general terms like \"Positive\" and \"Negative\" for overall satisfaction, consider using a numerical scale (e.g., 1-5) or a more detailed descriptive scale (e.g., \"Very Satisfied\", \"Satisfied\", \"Neutral\", \"Dissatisfied\", \"Very Dissatisfied\"). This would allow for a more nuanced expression of satisfaction levels.\\n\\n4. **Include Additional Feedback**: If there are any other aspects of the smartwatch or the user\\'s experience that were not captured in the initial table (such as customer support, additional features, or comparison to other products), consider adding them to the table or creating a separate section for \"Additional Comments\" or \"Overall Experience\".\\n\\n5. **Improve Table Readability**: While the table is currently easy to read, further improvements could be made by using bold text for column headers, aligning text properly within columns, or using different colors to highlight positive and negative feedback. Additionally, consider adding a legend or key to explain the satisfaction scale used in the table.',\n",
       " 'revised_response': '| **Feature**           | **Issue**                                                             | **Overall Satisfaction** |\\n|----------------------|------------------------------------------------------------------------|--------------------------|\\n| Notification System  | Difficulty in setting up; unclear user manual and online tutorials provided unexpected outcomes, such as failure to receive notifications | 2/5                      |\\n| Design               | Attractive and appealing design, with a comfortable fit and stylish appearance | 5/5                      |\\n| Battery Life         | Long-lasting battery life, exceeding expectations with up to 5 days of use on a single charge | 5/5                      |',\n",
       " 'judgement': 'Both assistants have provided a markdown table to organize the user\\'s feedback, which effectively addresses the user\\'s question. However, Assistant B\\'s table includes more detailed information in the \"Issue\" column for the Notification System, providing specific outcomes of the problem, such as the failure to receive notifications. Additionally, Assistant B uses a rating system (e.g., 2/5, 5/5) in the \"Overall Satisfaction\" column, which offers a more quantitative measure of satisfaction compared to Assistant A\\'s qualitative terms (Negative, Positive). This makes Assistant B\\'s response more informative and helpful for understanding the user\\'s experience with the smartwatch.',\n",
       " 'chosen_reponse': '| **Feature**           | **Issue**                                                             | **Overall Satisfaction** |\\n|----------------------|------------------------------------------------------------------------|--------------------------|\\n| Notification System  | Difficulty in setting up; unclear user manual and online tutorials provided unexpected outcomes, such as failure to receive notifications | 2/5                      |\\n| Design               | Attractive and appealing design, with a comfortable fit and stylish appearance | 5/5                      |\\n| Battery Life         | Long-lasting battery life, exceeding expectations with up to 5 days of use on a single charge | 5/5                      |'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_description': 'Convert the following unstructured user feedback into a structured markdown table.',\n",
       " 'seed_question': \"Been using the new dashboard for a few days. It's way faster than the previous one, really appreciate the snappy filters. But export to CSV seems broken â€” nothing happens when I click it. Also, dark mode resets every time I log in.\\n\\nI would like to convert the above feedback into a markdown table with columns for Feature, Feedback and Sentiment.\",\n",
       " 'seed_response': \"| Feature           | Feedback                                                           | Sentiment |\\n|------------------|--------------------------------------------------------------------|-----------|\\n| Dashboard        | Much faster than previous version, filters are responsive.         | Positive  |\\n| Export to CSV    | Clicking the export button doesn't trigger a download.             | Negative  |\\n| Dark Mode        | Resets to light mode on login.                                     | Negative  |\",\n",
       " 'question': \"I've been using the new software for a week now, and I'm impressed with the user interface and customization options. However, I've encountered several bugs, including a crash when trying to save a project. The customer support team has been responsive, but the solutions they provided didn't work. How can I convert this feedback into a markdown table with columns for Feature, Bug, and Support Experience?\",\n",
       " 'response': '| Feature           | Bug                                                              | Support Experience                   |\\n|------------------|------------------------------------------------------------------|--------------------------------------|\\n| User Interface   | None                                                             | N/A                                  |\\n| Customization    | None                                                             | N/A                                  |\\n| Project Saving   | Crashes when attempting to save a project.                       | Negative                             |\\n| Customer Support | Provided solutions did not resolve the issue.                    | Neutral                              |',\n",
       " 'route': 'coding',\n",
       " 'analysis': 'The task involves converting user feedback about a software into a markdown table. The domain of this task is software review and feedback analysis, specifically focusing on user experience, bug reporting, and customer support evaluation. The user is seeking a structured way to organize their feedback, highlighting positive aspects (features), negative experiences (bugs), and the effectiveness of the support team. The desired output is a markdown table with three columns: Feature, Bug, and Support Experience, which will help in summarizing the feedback in a clear and organized manner.',\n",
       " 'rubric': \"1. Accuracy: The markdown table should accurately reflect the user's feedback, correctly categorizing features, bugs, and support experiences.\\n2. Completeness: The table should include all relevant information from the feedback, ensuring no important details are omitted.\\n3. Formatting: The markdown table should be properly formatted, with clear and concise headings for each column (Feature, Bug, Support Experience) and correctly aligned rows.\\n4. Clarity: The information in the table should be easy to understand, with brief descriptions that clearly convey the user's experience with each feature, bug, and support interaction.\\n5. Organization: The table should be well-organized, making it easy to compare and contrast different aspects of the user's experience with the software.\",\n",
       " 'critique': '1. Accuracy: The markdown table accurately reflects the user\\'s feedback, correctly categorizing features, bugs, and support experiences. However, the \"Customer Support\" row seems slightly out of place as it doesn\\'t fit neatly into the feature or bug category but rather comments on the support experience as a whole. It might be more accurate to have a separate section or table for support interactions to maintain clarity.\\n\\n2. Completeness: The table includes most of the relevant information from the feedback but could be more comprehensive. For example, the feedback mentions being \"impressed with the user interface and customization options,\" which is captured, but the negative aspect of the support experience (solutions not working) could be elaborated upon for completeness. Additionally, the initial positive interaction with the support team (being \"responsive\") is somewhat downplayed by categorizing the overall support experience as \"Neutral\" without further explanation.\\n\\n3. Formatting: The markdown table is properly formatted with clear and concise headings for each column and correctly aligned rows. The use of \"N/A\" for features without bugs or support experiences related to them is appropriate and helps maintain table readability.\\n\\n4. Clarity: The descriptions in the table are brief and generally clear. However, the \"Support Experience\" column could benefit from more detailed explanations to provide a fuller understanding of the user\\'s interactions with the support team. For instance, instead of just \"Negative\" for the project saving bug, it could explain that the support solutions did not resolve the issue, and similarly, the \"Neutral\" support experience could be expanded upon.\\n\\n5. Organization: The table is well-organized, making it easy to scan and understand the different aspects of the user\\'s experience. The separation of features, bugs, and support experiences into distinct rows allows for a clear comparison of the positive and negative aspects of the software. Consideration could be given to grouping related features or bugs together for an even clearer overview, but the current organization is effective.',\n",
       " 'plan': '1. Refine the Table Structure: Consider adding a separate section or table for support interactions to improve accuracy and clarity. This could involve creating a \"Support Interactions\" table with columns for Issue, Support Response, and Outcome to provide a detailed view of the user\\'s experience with the support team.\\n\\n2. Enhance Completeness: Elaborate on the support experience by including more details about the interactions, such as the responsiveness of the support team and the ineffectiveness of the provided solutions. This could involve adding more rows to the table to capture each significant interaction or outcome.\\n\\n3. Improve Formatting for Readability: While the current formatting is clear, consider using additional markdown features such as bolding or italicizing important information (e.g., critical bugs or significant support issues) to draw attention to key points.\\n\\n4. Increase Clarity in Descriptions: Expand the descriptions in the \"Support Experience\" column to provide a fuller understanding of the user\\'s interactions with the support team. For example, instead of \"Neutral,\" describe the experience as \"The support team was responsive but the solutions provided did not resolve the issue, leading to a neutral assessment of the support experience.\"\\n\\n5. Organizational Adjustments: Consider grouping related features or bugs together. For instance, if there were multiple bugs related to project management, grouping these could provide a clearer overview of the software\\'s performance in specific areas. This could involve using subheadings within the table or creating separate tables for different categories of features or bugs.\\n\\n6. Add a Summary Section: Include a summary section below the table to highlight the key points from the feedback, such as the most significant bugs, the overall satisfaction with the support team, and any recommendations for improvement. This summary can help in quickly understanding the essence of the feedback without needing to read through the entire table.\\n\\n7. Review and Test: Finally, review the revised table and summary for accuracy, completeness, and clarity. Test the readability and effectiveness of the table in conveying the user\\'s feedback by sharing it with others and gathering their feedback on its usefulness and ease of understanding.',\n",
       " 'revised_response': \"| Feature           | Bug                                                              | Support Experience                   |\\n|------------------|------------------------------------------------------------------|--------------------------------------|\\n| User Interface   | None                                                             | Positive: Impressed with the interface|\\n| Customization    | None                                                             | Positive: Customization options are user-friendly |\\n| Project Saving   | Crashes when attempting to save a project.                       | Negative: Solutions provided by support did not resolve the issue       |\\n| Customer Support | Provided solutions did not resolve the issue.                    | Mixed: Support team was responsive but solutions were ineffective      |\\n\\n### Support Interactions Table\\n| Issue            | Support Response                                              | Outcome                             |\\n|-----------------|--------------------------------------------------------------|-------------------------------------|\\n| Project Saving Bug | Provided troubleshooting steps and potential fixes.       | Issue not resolved; solutions ineffective |\\n| Initial Contact  | Responsive, acknowledged the issue, and promised a solution. | Ongoing support interaction          |\\n\\n### Summary\\nThe user is generally satisfied with the software's user interface and customization options. However, a critical bug causing the software to crash when saving a project significantly impacts the user experience. Despite the support team's responsiveness, the solutions provided did not resolve the issue, leading to a mixed assessment of the support experience. Key recommendations for improvement include addressing the project saving bug and enhancing the support team's ability to provide effective solutions.\",\n",
       " 'judgement': \"Both assistants provide a markdown table as requested, but they differ in detail and additional information. Assistant A's table is straightforward, listing the features, bugs, and support experiences. However, it lacks depth in the support experience column, simply marking it as negative or neutral without elaboration. Assistant B, on the other hand, provides a more detailed table with specific comments on the support experience, including both positive and negative aspects. Additionally, Assistant B includes a secondary table detailing the support interactions, which offers a clearer picture of the issues faced and the outcomes of the support requests. Assistant B also provides a summary that encapsulates the user's experience, highlighting both the satisfactory and unsatisfactory aspects, and suggests areas for improvement. This comprehensive approach makes Assistant B's response more informative and helpful.\",\n",
       " 'chosen_reponse': \"| Feature           | Bug                                                              | Support Experience                   |\\n|------------------|------------------------------------------------------------------|--------------------------------------|\\n| User Interface   | None                                                             | Positive: Impressed with the interface|\\n| Customization    | None                                                             | Positive: Customization options are user-friendly |\\n| Project Saving   | Crashes when attempting to save a project.                       | Negative: Solutions provided by support did not resolve the issue       |\\n| Customer Support | Provided solutions did not resolve the issue.                    | Mixed: Support team was responsive but solutions were ineffective      |\\n\\n### Support Interactions Table\\n| Issue            | Support Response                                              | Outcome                             |\\n|-----------------|--------------------------------------------------------------|-------------------------------------|\\n| Project Saving Bug | Provided troubleshooting steps and potential fixes.       | Issue not resolved; solutions ineffective |\\n| Initial Contact  | Responsive, acknowledged the issue, and promised a solution. | Ongoing support interaction          |\\n\\n### Summary\\nThe user is generally satisfied with the software's user interface and customization options. However, a critical bug causing the software to crash when saving a project significantly impacts the user experience. Despite the support team's responsiveness, the solutions provided did not resolve the issue, leading to a mixed assessment of the support experience. Key recommendations for improvement include addressing the project saving bug and enhancing the support team's ability to provide effective solutions.\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdg-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
